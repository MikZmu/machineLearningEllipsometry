{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "481037fb-e897-4e88-a13b-aa844eaa9003",
   "metadata": {},
   "source": [
    "Poniżej zamieszczam kod, który umożliwia przewidzenie w wartości T, A, B lub C dla jednego pliku. Pliki znajdują się w folderze datasets/new_Si_jaw_delta.\n",
    "Wartości T, A, B, C dla poszczególnych plików są zakodowane w ich nazwach -> T_A_B_C. Aby dokonać przewidywania na pliku modelem uczonym na\n",
    "nieustandaryzowanym zestawie danych należy wywołać funkcję predict. Funkcja przyjmuje jako argumenty zestaw danych (plik txt) oraz model. Wszystkie\n",
    "modele posiadają 7 wejść oraz 1 wyjście. Wartość X przewidywana przez model, ilość warstw ukrytych w modelu oraz ilość neuronów w każdej warstwie są\n",
    "zapisane w nazwie modelu w następujący sposób - \"modelX_neuronyW1warstwieukrytej_neuronyW2warstwieukrytej_...\". Modele uczone na danych standaryzowanych zawierają w sobie frazę \"standard\". Aby przewidzieć wartość za pomocą modelu\n",
    "uczonego na danych standaryzowanych należy użyć funkcji predict_scaled. Przyjmuje ona jako argumenty także nazwy scalerów dla feature'ów i targetu.\n",
    "Przeznaczenie scalera jest opisane w jego nazwie - np. bScaler_featureScaler.pkl jest scalerem użytym dla skalowania feature'ów zastosowanych do uczenia modeli przewidujących wartość B. Funkcję należy wywołać na dole drugiej komórki.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "166fff38-7a58-43ad-b46e-77399906875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, activation_fn=nn.ReLU):\n",
    "\n",
    "        super(MLP, self).__init__()\n",
    "        if len(hidden_layers) > 8:\n",
    "            raise ValueError(\"The number of hidden layers cannot exceed 8.\")\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        prev_size = input_size\n",
    "\n",
    "        # Create hidden layers\n",
    "        for neurons in hidden_layers:\n",
    "            self.layers.append(nn.Linear(prev_size, neurons))\n",
    "            self.layers.append(activation_fn())  # Add the specified activation function\n",
    "            prev_size = neurons\n",
    "\n",
    "        # Create output layer\n",
    "        self.layers.append(nn.Linear(prev_size, output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef0fa728-a5dc-4d60-81b8-2ef19fe2a53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.848_1.3902_0.01375279_0.00019072660000000002.txt\n",
      "modelT_48_32_16_8.pth\n",
      "x\n",
      "[48, 32, 16, 8]\n",
      "Model prediction: 95.28948211669922\n",
      "94.848_1.3902_0.01375279_0.00019072660000000002.txt\n",
      "modelCstandard_256_128_64_32.pth\n",
      "cScaler_featureScaler.pkl\n",
      "cScaler_targetScaler.pkl\n",
      "x\n",
      "[256, 128, 64, 32]\n",
      "Model prediction: 0.00012547629012260586\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import layout\n",
    "import statistics\n",
    "\n",
    "\n",
    "project_folder = os.getcwd()\n",
    "folder_path = os.path.join(project_folder,\"datasets\", \"new_Si_jaw_delta\", \"\")\n",
    "all_items = os.listdir(folder_path)\n",
    "files = [item for item in all_items if os.path.isfile(os.path.join(folder_path, item))]\n",
    "\n",
    "def extract_from_name(name):\n",
    "    dataHelper = pd.read_csv(folder_path + name, sep='\\t', header=None, index_col=False)\n",
    "    info = name.split('_')\n",
    "    T = info[0]\n",
    "    A = info[1]\n",
    "    B = info[2]\n",
    "    C = info[3]\n",
    "    dataHelper = dataHelper.drop(index=[0])\n",
    "    dataHelper = dataHelper.drop(columns=[7])\n",
    "    dataHelper.columns = ['wavelength', 'psi65', 'del65', 'psi70', 'del70', 'psi75', 'del75']\n",
    "    dataHelper['T'] = T\n",
    "    dataHelper['A'] = A\n",
    "    dataHelper['B'] = B\n",
    "    C = C.removesuffix(\".txt\")\n",
    "    print('x')\n",
    "    if (\"-\" in C):\n",
    "        C = C.removesuffix(\"e-\")\n",
    "        C = float(C) * 10 ** -5\n",
    "    elif (\"e\" in C):\n",
    "        C = C.removesuffix(\"e\")\n",
    "        C = float(C) * 10 ** -5\n",
    "\n",
    "    if (float(C) > 1):\n",
    "        C = float(C) * 10 ** -5\n",
    "\n",
    "    dataHelper['C'] = C\n",
    "\n",
    "    return dataHelper\n",
    "\n",
    "def decode_model(model):\n",
    "    model = model.removesuffix(\".pth\")\n",
    "    layers = model.split('_')\n",
    "    layers.pop(0)\n",
    "    return list(map(int, layers))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict(file, model):\n",
    "    print(file)\n",
    "    print(model)\n",
    "    dataHelper = extract_from_name(file)\n",
    "    x = dataHelper[['wavelength', 'psi65', 'del65', 'psi70', 'del70', 'psi75', 'del75']]\n",
    "    x = torch.from_numpy(x.values).float()\n",
    "    layers = decode_model(model)\n",
    "    print(layers)\n",
    "    mModel = MLP(input_size=7, output_size=1, hidden_layers=layers)\n",
    "    if torch.cuda.is_available():\n",
    "        mModel.load_state_dict(torch.load(model))\n",
    "    else:\n",
    "        mModel.load_state_dict(torch.load(model, map_location=torch.device('cpu')))\n",
    "\n",
    "    values = []\n",
    "\n",
    "    for i in x:\n",
    "        with torch.no_grad():\n",
    "            values.append(mModel(i).item())\n",
    "\n",
    "    print(f\"Model prediction: {statistics.median(values)}\" )\n",
    "\n",
    "\n",
    "\n",
    "def predict_scaled(file, model, scaler, targetscaler):\n",
    "    print(file)\n",
    "    print(model)\n",
    "    print(scaler)\n",
    "    print(targetscaler)\n",
    "    dataHelper = extract_from_name(file)\n",
    "    x = dataHelper[['wavelength', 'psi65', 'del65', 'psi70', 'del70', 'psi75', 'del75']]\n",
    "    x = torch.from_numpy(x.values).float()\n",
    "    layers = decode_model(model)\n",
    "    print(layers)\n",
    "    mModel = MLP(input_size=7, output_size=1, hidden_layers=layers)\n",
    "    if torch.cuda.is_available():\n",
    "        mModel.load_state_dict(torch.load(model))\n",
    "    else:\n",
    "        mModel.load_state_dict(torch.load(model, map_location=torch.device('cpu')))\n",
    "\n",
    "    featureNames = ['wavelength', 'psi65', 'del65', 'psi70', 'del70', 'psi75', 'del75']\n",
    "    featureScaler = joblib.load(scaler)\n",
    "    targetScaler = joblib.load(targetscaler)\n",
    "    values = []\n",
    "    for i in x:\n",
    "        i_df = pd.DataFrame(i.numpy().reshape(1, -1), columns=featureNames)\n",
    "        iScaled = featureScaler.transform(i_df)\n",
    "        with torch.no_grad():\n",
    "            pred = mModel(torch.from_numpy(iScaled).float())\n",
    "            numpyPred = pred.detach().cpu().numpy()\n",
    "            predInv = targetScaler.inverse_transform(numpyPred)\n",
    "            values.append(predInv.item())\n",
    "\n",
    "    print(f\"Model prediction: {statistics.median(values)}\")\n",
    "    \n",
    "\n",
    "predict(\"94.848_1.3902_0.01375279_0.00019072660000000002.txt\", \"modelT_48_32_16_8.pth\")\n",
    "predict_scaled(\"94.848_1.3902_0.01375279_0.00019072660000000002.txt\", \"modelCstandard_256_128_64_32.pth\", \"cScaler_featureScaler.pkl\", \"cScaler_targetScaler.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ef787-c3bc-4591-9b3c-9ca492e479c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
