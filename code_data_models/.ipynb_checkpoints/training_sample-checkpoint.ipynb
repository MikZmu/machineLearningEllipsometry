{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70bfca93-cea6-4fec-b93c-c019e6461777",
   "metadata": {},
   "source": [
    "This class describes data regarding single sample - it contains measurements of PSI and DEL for 3 different angles of incidence (65, 70, 75 degrees) and the wavelength of the light used in the experiment. It is meant to provide functions that will allow for making predictions regarding single sample. It is meant to be used only for samples that will be used for training - it assumes that values of thickness and A, B, C parameters are contained within file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d197f983-785f-42b0-a926-c4c82314d577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import import_ipynb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.datasets import load_sample_image\n",
    "import model_creator\n",
    "\n",
    "\n",
    "class training_sample:\n",
    "\n",
    "    def __init__(self, file_path):\n",
    "        # Initialize the training_sample object by decoding the file name to extract parameters\n",
    "        # and loading the data from the file.\n",
    "        self.T = self.decode_sample(file_path)[0]\n",
    "        self.A = self.decode_sample(file_path)[1]\n",
    "        self.B = self.decode_sample(file_path)[2]\n",
    "        self.C = self.decode_sample(file_path)[3]\n",
    "        self.data = self.load_data(file_path, self.T, self.A, self.B, self.C)\n",
    "\n",
    "\n",
    "    def decode_sample(self, filename):\n",
    "        \"\"\"\n",
    "        Decodes the file name to extract sample parameters (T, A, B, C).\n",
    "    \n",
    "        Parameters:\n",
    "        - filename: str, the name of the file to decode.\n",
    "    \n",
    "        Returns:\n",
    "        - list: A list containing the extracted parameters [T, A, B, C].\n",
    "        \"\"\"\n",
    "        filename = os.path.basename(filename)\n",
    "        info = filename.split(\"_\")\n",
    "        T = info[0]\n",
    "        A = info[1]\n",
    "        B = info[2]\n",
    "        C = info[3]\n",
    "        C = C.removesuffix(\".txt\")\n",
    "        return [T, A, B, C]\n",
    "\n",
    "\n",
    "    def load_data(self, filename, T, A, B, C):\n",
    "        \"\"\"\n",
    "        Loads the data from the file, cleans it, and adds the sample parameters as columns.\n",
    "    \n",
    "        Parameters:\n",
    "        - filename: str, the name of the file to load.\n",
    "        - T: str, sample parameter T.\n",
    "        - A: str, sample parameter A.\n",
    "        - B: str, sample parameter B.\n",
    "        - C: str, sample parameter C.\n",
    "    \n",
    "        Returns:\n",
    "        - pandas.DataFrame: The cleaned and processed data with added sample parameters.\n",
    "        \"\"\"\n",
    "        dataHelper = pd.read_csv(filename, sep='\\t', header=None, index_col=False)\n",
    "        dataHelper = dataHelper.drop(index=[0])\n",
    "        dataHelper = dataHelper.drop(columns=[7])\n",
    "        dataHelper.columns = ['wavelength', 'psi65', 'del65', 'psi70', 'del70', 'psi75', 'del75']\n",
    "        dataHelper['T'] = T\n",
    "        dataHelper['A'] = A\n",
    "        dataHelper['B'] = B\n",
    "        dataHelper['C'] = C\n",
    "        return dataHelper\n",
    "\n",
    "    def return_as_2dlist(self, feature_columns = ['wavelength', 'psi65', 'del65', 'psi70', 'del70', 'psi75', 'del75'], target_columns = ['T', 'A', 'B', 'C']):\n",
    "\n",
    "        \"\"\"\n",
    "        Returns the features and targets as separate 2D lists.\n",
    "    \n",
    "        Parameters:\n",
    "        - feature_columns: list, names of the columns to use as features.\n",
    "        - target_columns: list, names of the columns to use as targets.\n",
    "    \n",
    "        Returns:\n",
    "        - tuple: A tuple containing two 2D lists (features, targets).\n",
    "        \"\"\"\n",
    "        features = self.data[feature_columns]\n",
    "        targets = self.data[target_columns]\n",
    "        return features, targets\n",
    "\n",
    "    def return_as_tensors(self, feature_columns = ['wavelength', 'psi65', 'del65', 'psi70', 'del70', 'psi75', 'del75'], target_columns = ['T', 'A', 'B', 'C']):\n",
    "        \"\"\"\n",
    "        Converts the features and targets into PyTorch tensors.\n",
    "    \n",
    "        Parameters:\n",
    "        - feature_columns: list, names of the columns to use as features.\n",
    "        - target_columns: list, names of the columns to use as targets.\n",
    "    \n",
    "        Returns:\n",
    "        - tuple: A tuple containing two PyTorch tensors (features, targets).\n",
    "        \"\"\"\n",
    "        features = self.data[feature_columns]\n",
    "        targets = self.data[target_columns]\n",
    "        features = torch.from_numpy(features.to_numpy(dtype=np.float32))\n",
    "        targets = torch.from_numpy(targets.to_numpy(dtype=np.float32))\n",
    "        return features, targets\n",
    "\n",
    "    def return_as_flat_df(self, feature_columns = ['wavelength', 'psi65', 'del65', 'psi70', 'del70', 'psi75', 'del75'], target_columns = ['T', 'A', 'B', 'C']):\n",
    "        \"\"\"\n",
    "        Flattens the features and targets into a single row and returns them as DataFrames.\n",
    "    \n",
    "        Parameters:\n",
    "        - feature_columns: list, names of the columns to use as features.\n",
    "        - target_columns: list, names of the columns to use as targets.\n",
    "    \n",
    "        Returns:\n",
    "        - tuple: A tuple containing two pandas DataFrames (features, targets).\n",
    "        \"\"\"\n",
    "        features = self.data[feature_columns]\n",
    "        targets = self.data[target_columns]\n",
    "        targets = targets.iloc[:1]\n",
    "        features = features.values.reshape(1, -1)\n",
    "        targets = targets.values.reshape(1, -1)\n",
    "        features = pd.DataFrame(features)\n",
    "        targets = pd.DataFrame(targets)\n",
    "        return features, targets\n",
    "\n",
    "    def return_as_flat_tensors(self,feature_columns=['wavelength', 'psi65', 'del65', 'psi70', 'del70', 'psi75', 'del75'],target_columns=['T', 'A', 'B', 'C']):\n",
    "\n",
    "        \"\"\"\n",
    "        Flattens the features and targets into a single row and returns them as PyTorch tensors.\n",
    "    \n",
    "        Parameters:\n",
    "        - feature_columns: list, names of the columns to use as features.\n",
    "        - target_columns: list, names of the columns to use as targets.\n",
    "    \n",
    "        Returns:\n",
    "        - tuple: A tuple containing two PyTorch tensors (features, targets).\n",
    "        \"\"\"\n",
    "        features = self.data[feature_columns]\n",
    "        targets = self.data[target_columns]\n",
    "        features = torch.from_numpy(features.to_numpy(dtype=np.float32))\n",
    "        targets = torch.from_numpy(targets.to_numpy(dtype=np.float32))\n",
    "        features = features.reshape(1, -1)\n",
    "        targets = targets[:1]\n",
    "        targets = targets.reshape(1, -1)\n",
    "        return features, targets\n",
    "\n",
    "    def features_as_tensors(self, feature_columns = ['wavelength', 'psi65', 'del65', 'psi70', 'del70', 'psi75', 'del75']):\n",
    "\n",
    "        \"\"\"\n",
    "        Converts the features into PyTorch tensors.\n",
    "    \n",
    "        Parameters:\n",
    "        - feature_columns: list, names of the columns to use as features.\n",
    "    \n",
    "        Returns:\n",
    "        - torch.Tensor: A PyTorch tensor containing the features.\n",
    "        \"\"\"\n",
    "        features = self.data[feature_columns]\n",
    "        features = torch.from_numpy(features.to_numpy(dtype=np.float32))\n",
    "        return features\n",
    "\n",
    "    def predict_mean(self, model_name, features, output_size):\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Predicts the mean of the model's output for the given features.\n",
    "    \n",
    "        Parameters:\n",
    "        - model_nameh: str, name of model file.\n",
    "        - features: pandas.DataFrame, the features to use for prediction.\n",
    "        - output_size: int, the size of the model's output.\n",
    "    \n",
    "        Returns:\n",
    "        - float: The mean of the model's predictions.\n",
    "        \"\"\"\n",
    "        model = model_creator.MLP.create_and_load(model_name,len(features), output_size)\n",
    "        model.eval()\n",
    "        features_as_tensors = self.features_as_tensors(features)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(features_as_tensors)\n",
    "        predictions = predictions.flatten().tolist()\n",
    "        mean = np.mean(predictions)\n",
    "        return mean\n",
    "\n",
    "    def return_standarized(self, scaler, columns):\n",
    "\n",
    "        \"\"\"\n",
    "        Standardizes the specified columns of the data using the provided scaler.\n",
    "    \n",
    "        Parameters:\n",
    "        - scaler: sklearn scaler object, the scaler to use for standardization.\n",
    "        - columns: list, names of the columns to standardize.\n",
    "    \n",
    "        Returns:\n",
    "        - numpy.ndarray: The standardized data.\n",
    "        \"\"\"\n",
    "        data = self.data[columns]\n",
    "        data = scaler.transform(data)\n",
    "        return data\n",
    "\n",
    "    def get_sample_info(self):\n",
    "        \"\"\"\n",
    "        Returns the sample parameters (T, A, B, C) as a tuple.\n",
    "    \n",
    "        Parameters:\n",
    "        - None\n",
    "    \n",
    "        Returns:\n",
    "        - tuple: A tuple containing the sample parameters (T, A, B, C).\n",
    "        \"\"\"\n",
    "        return self.T, self.A, self.B, self.C\n",
    "\n",
    "    def print_sample_info(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Prints the sample parameters (T, A, B, C).\n",
    "    \n",
    "        Parameters:\n",
    "        - None\n",
    "    \n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        print(f'T: {self.T}, A: {self.A}, B: {self.B}, C: {self.C}')\n",
    "\n",
    "\n",
    "    def predict_median(self, model_name, features, output_size):\n",
    "        \"\"\"\n",
    "        Predicts the median of the model's output for the given features.\n",
    "    \n",
    "        Parameters:\n",
    "        - model_name: str, name of model file\n",
    "        - features: pandas.DataFrame, the features to use for prediction.\n",
    "        - output_size: int, the size of the model's output.\n",
    "    \n",
    "        Returns:\n",
    "        - float: The median of the model's predictions.\n",
    "        \"\"\"\n",
    "        model = model_creator.MLP.create_and_load(model, features.shape[1], output_size)\n",
    "        model.eval()\n",
    "        features_as_tensors = self.features_as_tensors(features)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(features_as_tensors)\n",
    "        predictions = predictions.flatten().tolist()\n",
    "        median = np.median(predictions)\n",
    "        return median\n",
    "\n",
    "    def plot_polynomial_fit(data, x_column, y_column, degree):\n",
    "        \"\"\"\n",
    "        Approximates the relationship between two columns in the data with a polynomial of a given degree\n",
    "        and plots the result.\n",
    "    \n",
    "        Parameters:\n",
    "        - data: pandas DataFrame containing the data.\n",
    "        - x_column: str, name of the column to use as the X-axis.\n",
    "        - y_column: str, name of the column to use as the Y-axis.\n",
    "        - degree: int, degree of the polynomial to fit.\n",
    "    \n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        # Extract X and Y data\n",
    "        X = data[x_column].values.reshape(-1, 1)\n",
    "        Y = data[y_column].values\n",
    "    \n",
    "        # Create polynomial features\n",
    "        poly = PolynomialFeatures(degree=degree)\n",
    "        X_poly = poly.fit_transform(X)\n",
    "    \n",
    "        # Fit the polynomial regression model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_poly, Y)\n",
    "    \n",
    "        # Generate predictions\n",
    "        X_range = np.linspace(X.min(), X.max(), 500).reshape(-1, 1)\n",
    "        X_range_poly = poly.transform(X_range)\n",
    "        Y_pred = model.predict(X_range_poly)\n",
    "    \n",
    "        # Plot the data and the polynomial fit\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(X, Y, color='blue', label='Data', alpha=0.7)\n",
    "        plt.plot(X_range, Y_pred, color='red', label=f'Polynomial Fit (degree={degree})')\n",
    "        plt.xlabel(x_column)\n",
    "        plt.ylabel(y_column)\n",
    "        plt.title(f'Polynomial Fit of {y_column} vs {x_column}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_columns(data, x_column, y_column):\n",
    "        \"\"\"\n",
    "        Plots two columns from the data without any fitting.\n",
    "    \n",
    "        Parameters:\n",
    "        - data: pandas DataFrame containing the data.\n",
    "        - x_column: str, name of the column to use as the X-axis.\n",
    "        - y_column: str, name of the column to use as the Y-axis.\n",
    "    \n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        # Extract X and Y data\n",
    "        X = data[x_column]\n",
    "        Y = data[y_column]\n",
    "    \n",
    "        # Plot the data\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(X, Y, color='blue', label='Data', alpha=0.7)\n",
    "        plt.xlabel(x_column)\n",
    "        plt.ylabel(y_column)\n",
    "        plt.title(f'{y_column} vs {x_column}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b32ed1-7e6e-4b2a-8217-76836ff0c679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
