{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c71f59a-e3ac-4018-a776-b13e992f1aea",
   "metadata": {},
   "source": [
    "Poniższy kod służył demonstracji przeuczenia modeli używających danych standaryzowanych.\n",
    "Modele zostały jednak prawdopodobnie dotknięte poprzez dokonywanie przewidywań bez użycia torch.no_grad(), co spowodowało że wartości R2 dla obu zbiorów wyrównały się"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10038c7b-6a85-494a-a444-c59ae851da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\machineLearningEllipsometry\\code_data_models\n",
      "D:\\ML\\machineLearningEllipsometry\\code_data_models\\datasets\\new_Si_jaw_delta\\\n",
      "D:\\ML\\machineLearningEllipsometry\\code_data_models\\models\\\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([('wavelength', 'psi65', 'del65', 'psi70', 'del70', 'psi75', 'del75')], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     31\u001b[39m half_data_folder = os.path.join(parent_folder,\u001b[33m\"\u001b[39m\u001b[33mdatasets\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhalf_new_Si_jaw_delta\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m quarter_data_folder = os.path.join(parent_folder,\u001b[33m\"\u001b[39m\u001b[33mdatasets\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mquarter_new_Si_jaw_delta\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m Adata = \u001b[43mdata_acquisition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetData\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwavelength\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpsi65\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdel65\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpsi70\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdel70\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpsi75\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdel75\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mA\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m Bdata = data_acquisition.getData([\u001b[33m\"\u001b[39m\u001b[33mwavelength\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mpsi65\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdel65\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpsi70\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdel70\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpsi75\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdel75\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m], folder_path)\n\u001b[32m     39\u001b[39m Cdata = data_acquisition.getData([\u001b[33m\"\u001b[39m\u001b[33mwavelength\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mpsi65\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdel65\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpsi70\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdel70\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpsi75\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdel75\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m], folder_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:41\u001b[39m, in \u001b[36mgetData\u001b[39m\u001b[34m(feature_columns, target_columns, folder)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6252\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index([('wavelength', 'psi65', 'del65', 'psi70', 'del70', 'psi75', 'del75')], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import os\n",
    "import import_ipynb\n",
    "import torch\n",
    "\n",
    "import data_acquisition\n",
    "\n",
    "import model_creator\n",
    "\n",
    "from single_file_prediction import decode_model\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def create_and_load(model_folder,model_name, input_size, output_size):\n",
    "    model_path = os.path.join(model_folder, model_name)\n",
    "    model = model_creator.MLP(input_size, output_size, hidden_layers=decode_model(model_name))\n",
    "    if torch.cuda.is_available():\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    return model\n",
    "\n",
    "def list_to_float(lst):\n",
    "    return [float(i) for i in lst]\n",
    "\n",
    "parent_folder = os.getcwd()\n",
    "print(parent_folder)\n",
    "folder_path = os.path.join(parent_folder,\"datasets\", \"new_Si_jaw_delta\", \"\")\n",
    "print(folder_path)\n",
    "model_folder = os.path.join(parent_folder,\"models\" ,\"\")\n",
    "print(model_folder)\n",
    "half_data_folder = os.path.join(parent_folder,\"datasets\", \"half_new_Si_jaw_delta\", \"\")\n",
    "quarter_data_folder = os.path.join(parent_folder,\"datasets\", \"quarter_new_Si_jaw_delta\", \"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Adata = data_acquisition.getData([\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"A\"], folder_path)\n",
    "Bdata = data_acquisition.getData([\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"B\"], folder_path)\n",
    "Cdata = data_acquisition.getData([\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"C\"], folder_path)\n",
    "Csdata = data_acquisition.get_Standarized_data(\"cScaler\",[\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"C\"], folder_path)\n",
    "Bsdata = data_acquisition.get_Standarized_data(\"bScaler\",[\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"B\"], folder_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_set_r2(model, x,y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)\n",
    "        pred = pred.flatten().tolist()\n",
    "    y= y.flatten().tolist()\n",
    "    return (pearsonr(pred, y)[0]**2)\n",
    "\n",
    "def calculate_r2(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predTrain = model(data[0])\n",
    "        predTrain = predTrain.flatten().tolist()\n",
    "        predTest = model(data[2])\n",
    "        predTest = predTest.flatten().tolist()\n",
    "        yTrain = data[1].flatten().tolist()\n",
    "        yTest = data[3].flatten().tolist()\n",
    "    return ([pearsonr(predTrain, yTrain)[0]**2, pearsonr(predTest, yTest)[0]**2])\n",
    "\n",
    "A_32_16_16_8 = create_and_load(model_folder, \"modelA_32_16_16_8.pth\", 7, 1)\n",
    "print(f\"modelA_32_16_16_8 R2 Train: {calculate_r2(A_32_16_16_8, Adata)[0]} Test: {calculate_r2(A_32_16_16_8, Adata)[1]}\")\n",
    "A_48_32_24_12 = create_and_load(model_folder, \"modelA_48_32_24_12.pth\", 7, 1)\n",
    "print(f\"modelA_48_32_24_12 R2 Train: {calculate_r2(A_48_32_24_12, Adata)[0]} Test: {calculate_r2(A_48_32_24_12, Adata)[1]}\")\n",
    "A_64_32_32_16 = create_and_load(model_folder, \"modelA_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelA_64_32_32_16 R2 Train: {calculate_r2(A_64_32_32_16, Adata)[0]} Test: {calculate_r2(A_64_32_32_16, Adata)[1]}\")\n",
    "B_32_16_16_8 = create_and_load(model_folder, \"modelB_32_16_16_8.pth\", 7, 1)\n",
    "print(f\"modelB_32_16_16_8 R2 Train: {calculate_r2(B_32_16_16_8, Bdata)[0]} Test: {calculate_r2(B_32_16_16_8, Bdata)[1]}\")\n",
    "B_48_32_24_12 = create_and_load(model_folder, \"modelB_48_32_24_12.pth\", 7, 1)\n",
    "print(f\"modelB_48_32_24_12 R2 Train: {calculate_r2(B_48_32_24_12, Bdata)[0]} Test: {calculate_r2(B_48_32_24_12, Bdata)[1]}\")\n",
    "B_64_32_32_16 = create_and_load(model_folder, \"modelB_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelB_64_32_32_16 R2 Train: {calculate_r2(B_64_32_32_16, Bdata)[0]} Test: {calculate_r2(B_64_32_32_16, Bdata)[1]}\")\n",
    "C_32_16_16_8 = create_and_load(model_folder, \"modelC_32_16_16_8.pth\", 7, 1)\n",
    "print(f\"modelC_32_16_16_8 R2 Train: {calculate_r2(C_32_16_16_8, Cdata)[0]} Test: {calculate_r2(C_32_16_16_8, Cdata)[1]}\")\n",
    "C_48_32_24_12 = create_and_load(model_folder, \"modelC_48_32_24_12.pth\", 7, 1)\n",
    "print(f\"modelC_48_32_24_12 R2 Train: {calculate_r2(C_48_32_24_12, Cdata)[0]} Test: {calculate_r2(C_48_32_24_12, Cdata)[1]}\")\n",
    "C_64_32_32_16 = create_and_load(model_folder, \"modelC_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelC_64_32_32_16 R2 Train: {calculate_r2(C_64_32_32_16, Cdata)[0]} Test: {calculate_r2(C_64_32_32_16, Cdata)[1]}\")\n",
    "\n",
    "Cst_32_16_16_8 = create_and_load(model_folder, \"modelCstandard_32_16_16_8.pth\", 7, 1)\n",
    "print(f\"modelCstandard_32_16_16_8 R2 Train: {calculate_r2(Cst_32_16_16_8, Csdata)[0]} Test: {calculate_r2(Cst_32_16_16_8, Csdata)[1]}\")\n",
    "Cst_48_32_24_12 = create_and_load(model_folder, \"modelCstandard_48_32_24_12.pth\", 7, 1)\n",
    "print(f\"modelCstandard_48_32_24_12 R2 Train: {calculate_r2(Cst_48_32_24_12, Csdata)[0]} Test: {calculate_r2(Cst_48_32_24_12, Csdata)[1]}\")\n",
    "Cst_64_32_32_16 = create_and_load(model_folder, \"modelCstandard_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelCstandard_64_32_32_16 R2 Train: {calculate_r2(Cst_64_32_32_16, Csdata)[0]} Test: {calculate_r2(Cst_64_32_32_16, Csdata)[1]}\")\n",
    "Bst_32_16_16_8 = create_and_load(model_folder, \"modelBstandard_32_16_16_8.pth\", 7, 1)\n",
    "print(f\"modelBstandard_32_16_16_8 R2 Train: {calculate_r2(Bst_32_16_16_8, Bsdata)[0]} Test: {calculate_r2(Bst_32_16_16_8, Bsdata)[1]}\")\n",
    "Bst_48_32_24_12 = create_and_load(model_folder, \"modelBstandard_48_32_24_12.pth\", 7, 1)\n",
    "print(f\"modelBstandard_48_32_24_12 R2 Train: {calculate_r2(Bst_48_32_24_12, Bsdata)[0]} Test: {calculate_r2(Bst_48_32_24_12, Bsdata)[1]}\")\n",
    "Bst_64_32_32_16 = create_and_load(model_folder, \"modelBstandard_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelBstandard_64_32_32_16 R2 Train: {calculate_r2(Bst_64_32_32_16, Bsdata)[0]} Test: {calculate_r2(Bst_64_32_32_16, Bsdata)[1]}\")\n",
    "\n",
    "csXdatacombined = torch.cat((Csdata[0], Csdata[2]), dim=0)\n",
    "csYdatacombined = torch.cat((Csdata[1], Csdata[3]), dim=0)\n",
    "bsXdatacombined = torch.cat((Bsdata[0], Bsdata[2]), dim=0)\n",
    "bsYdatacombined = torch.cat((Bsdata[1], Bsdata[3]), dim=0)\n",
    "\n",
    "print(f\"combined modelCstandard_64_32_32_16 R2: {calculate_set_r2(Cst_64_32_32_16, csXdatacombined, csYdatacombined)}\")\n",
    "print(f\"combined modelBstandard_64_32_32_16 R2: {calculate_set_r2(Bst_64_32_32_16, bsXdatacombined, bsYdatacombined)}\")\n",
    "print(f\"combined modelCstandard_48_32_24_12 R2: {calculate_set_r2(Cst_48_32_24_12, csXdatacombined, csYdatacombined)}\")\n",
    "print(f\"combined modelBstandard_48_32_24_12 R2: {calculate_set_r2(Bst_48_32_24_12, bsXdatacombined, bsYdatacombined)}\")\n",
    "print(f\"combined modelCstandard_32_16_16_8 R2: {calculate_set_r2(Cst_32_16_16_8, csXdatacombined, csYdatacombined)}\")\n",
    "print(f\"combined modelBstandard_32_16_16_8 R2: {calculate_set_r2(Bst_32_16_16_8, bsXdatacombined, bsYdatacombined)}\")\n",
    "\n",
    "\n",
    "\n",
    "cshalfdata = data_acquisition.get_Standarized_data(\"cScaler\",[\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"C\"], half_data_folder)\n",
    "bshalfdata = data_acquisition.get_Standarized_data(\"bScaler\",[\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"B\"], half_data_folder)\n",
    "\n",
    "\n",
    "c_half_64_32_32_16 = create_and_load(model_folder, \"modelhalfCstandard_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelhalfCstandard_64_32_32_16 R2 Train: {calculate_r2(c_half_64_32_32_16, cshalfdata)[0]} Test: {calculate_r2(c_half_64_32_32_16, cshalfdata)[1]}\")\n",
    "b_half_64_32_32_16 = create_and_load(model_folder, \"modelhalfBstandard_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelhalfBstandard_64_32_32_16 R2 Train: {calculate_r2(b_half_64_32_32_16, bshalfdata)[0]} Test: {calculate_r2(b_half_64_32_32_16, bshalfdata)[1]}\")\n",
    "\n",
    "cs_halfX_data_combined = torch.cat((cshalfdata[0], cshalfdata[2]), dim=0)\n",
    "cs_halfY_data_combined = torch.cat((cshalfdata[1], cshalfdata[3]), dim=0)\n",
    "bs_halfX_data_combined = torch.cat((bshalfdata[0], bshalfdata[2]), dim=0)\n",
    "bs_halfY_data_combined = torch.cat((bshalfdata[1], bshalfdata[3]), dim=0)\n",
    "\n",
    "print(f\"combined modelhalfCstandard_64_32_32_16 R2: {calculate_set_r2(c_half_64_32_32_16, cs_halfX_data_combined, cs_halfY_data_combined)}\")\n",
    "print(f\"combined modelhalfBstandard_64_32_32_16 R2: {calculate_set_r2(b_half_64_32_32_16, bs_halfX_data_combined, bs_halfY_data_combined)}\")\n",
    "\n",
    "\n",
    "\n",
    "cquarterdata = data_acquisition.get_Standarized_data(\"cScaler\",[\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"C\"], quarter_data_folder)\n",
    "bquarterdata = data_acquisition.get_Standarized_data(\"bScaler\",[\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"B\"], quarter_data_folder)\n",
    "\n",
    "\n",
    "c_quarter_64_32_32_16 = create_and_load(model_folder, \"modelquarterCstandard_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelquarterCstandard_64_32_32_16 R2 Train: {calculate_r2(c_quarter_64_32_32_16, cquarterdata)[0]} Test: {calculate_r2(c_quarter_64_32_32_16, cquarterdata)[1]}\")\n",
    "\n",
    "b_quarter_64_32_32_16 = create_and_load(model_folder, \"modelquarterBstandard_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelquarterBstandard_64_32_32_16 R2 Train: {calculate_r2(b_quarter_64_32_32_16, bquarterdata)[0]} Test: {calculate_r2(b_quarter_64_32_32_16, bquarterdata)[1]}\")\n",
    "\n",
    "\n",
    "cs_halfX_data_combined = torch.cat((cquarterdata[0], cquarterdata[2]), dim=0)\n",
    "cs_halfY_data_combined = torch.cat((cquarterdata[1], cquarterdata[3]), dim=0)\n",
    "bs_halfX_data_combined = torch.cat((bquarterdata[0], bquarterdata[2]), dim=0)\n",
    "bs_halfY_data_combined = torch.cat((bquarterdata[1], bquarterdata[3]), dim=0)\n",
    "print(f\"combined modelquarterCstandard_64_32_32_16 R2: {calculate_set_r2(c_quarter_64_32_32_16, cs_halfX_data_combined, cs_halfY_data_combined)}\")\n",
    "print(f\"combined modelquarterBstandard_64_32_32_16 R2: {calculate_set_r2(b_quarter_64_32_32_16, bs_halfX_data_combined, bs_halfY_data_combined)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8fb3a-c335-4907-9001-480a3e2c2210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
