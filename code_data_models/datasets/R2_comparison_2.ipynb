{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c71f59a-e3ac-4018-a776-b13e992f1aea",
   "metadata": {},
   "source": [
    "Poniższy kod służył demonstracji przeuczenia modeli używających danych standaryzowanych.\n",
    "Modele zostały jednak prawdopodobnie dotknięte poprzez dokonywanie przewidywań bez użycia torch.no_grad(), co spowodowało że wartości R2 dla obu zbiorów wyrównały się"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10038c7b-6a85-494a-a444-c59ae851da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ML\\machineLearningEllipsometry\\code_data_models\n",
      "D:\\ML\\machineLearningEllipsometry\\code_data_models\\datasets\\new_Si_jaw_delta\\\n",
      "D:\\ML\\machineLearningEllipsometry\\code_data_models\\models\\\n",
      "Index(['wavelength', 'psi65', 'del65', 'psi70', 'del70', 'psi75', 'del75', 'T',\n",
      "       'A', 'B', 'C'],\n",
      "      dtype='object')\n",
      "Index(['wavelength', 'psi65', 'del65', 'psi70', 'del70', 'psi75', 'del75', 'T',\n",
      "       'A', 'B', 'C'],\n",
      "      dtype='object')\n",
      "Index(['wavelength', 'psi65', 'del65', 'psi70', 'del70', 'psi75', 'del75', 'T',\n",
      "       'A', 'B', 'C'],\n",
      "      dtype='object')\n",
      "modelA_32_16_16_8 R2 Train: 0.00011678851442024538 Test: 8.305916212762277e-05\n",
      "modelA_48_32_24_12 R2 Train: 0.5751006872912109 Test: 0.5754834034695854\n",
      "modelA_64_32_32_16 R2 Train: 0.8666310627282557 Test: 0.8669853700383572\n",
      "modelB_32_16_16_8 R2 Train: 0.0003706631029938755 Test: 0.00031379856478570286\n",
      "modelB_48_32_24_12 R2 Train: 0.00018806464611163977 Test: 0.00017306850326510723\n",
      "modelB_64_32_32_16 R2 Train: 0.012359886570582302 Test: 0.012792513316184376\n",
      "modelC_32_16_16_8 R2 Train: 9.672948234510199e-06 Test: 3.956941470317622e-05\n",
      "modelC_48_32_24_12 R2 Train: 2.1622811736480232e-06 Test: 6.098620304157832e-05\n",
      "modelC_64_32_32_16 R2 Train: 2.2959894119410775e-05 Test: 0.00013276846687146354\n",
      "modelCstandard_32_16_16_8 R2 Train: 3.0586460074419095e-05 Test: 9.944754106159259e-06\n",
      "modelCstandard_48_32_24_12 R2 Train: 0.10856800766391199 Test: 0.11073258910546997\n",
      "modelCstandard_64_32_32_16 R2 Train: 0.13631446490777205 Test: 0.14530957551735138\n",
      "modelBstandard_32_16_16_8 R2 Train: 0.039178139282105076 Test: 0.04096514543217449\n",
      "modelBstandard_48_32_24_12 R2 Train: 0.19454122020062994 Test: 0.19627148807906128\n",
      "modelBstandard_64_32_32_16 R2 Train: 0.23427103206662178 Test: 0.23634190967454058\n",
      "combined modelCstandard_64_32_32_16 R2: 0.13803098012951256\n",
      "combined modelBstandard_64_32_32_16 R2: 0.23468575937710165\n",
      "combined modelCstandard_48_32_24_12 R2: 0.10900770783815801\n",
      "combined modelBstandard_48_32_24_12 R2: 0.19488762330016218\n",
      "combined modelCstandard_32_16_16_8 R2: 2.5604771686920555e-05\n",
      "combined modelBstandard_32_16_16_8 R2: 0.03953183808312507\n",
      "modelhalfCstandard_64_32_32_16 R2 Train: 0.2659549914056731 Test: 0.2606629219828068\n",
      "modelhalfBstandard_64_32_32_16 R2 Train: 0.3719035493840451 Test: 0.3756955501401441\n",
      "combined modelhalfCstandard_64_32_32_16 R2: 0.2648836622506027\n",
      "combined modelhalfBstandard_64_32_32_16 R2: 0.37264110704154474\n",
      "modelquarterCstandard_64_32_32_16 R2 Train: 0.5147413949029436 Test: 0.519594715969499\n",
      "modelquarterBstandard_64_32_32_16 R2 Train: 0.5631810890820098 Test: 0.5473951449449167\n",
      "combined modelquarterCstandard_64_32_32_16 R2: 0.5157393724985201\n",
      "combined modelquarterBstandard_64_32_32_16 R2: 0.5600314929565071\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import import_ipynb\n",
    "import torch\n",
    "\n",
    "import data_acquisition\n",
    "\n",
    "import model_creator\n",
    "\n",
    "from single_file_prediction import decode_model\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def create_and_load(model_folder,model_name, input_size, output_size):\n",
    "    model_path = os.path.join(model_folder, model_name)\n",
    "    model = model_creator.MLP(input_size, output_size, hidden_layers=decode_model(model_name))\n",
    "    if torch.cuda.is_available():\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    return model\n",
    "\n",
    "def list_to_float(lst):\n",
    "    return [float(i) for i in lst]\n",
    "\n",
    "parent_folder = os.getcwd()\n",
    "print(parent_folder)\n",
    "folder_path = os.path.join(parent_folder,\"datasets\", \"new_Si_jaw_delta\", \"\")\n",
    "print(folder_path)\n",
    "model_folder = os.path.join(parent_folder,\"models\" ,\"\")\n",
    "print(model_folder)\n",
    "half_data_folder = os.path.join(parent_folder,\"datasets\", \"half_new_Si_jaw_delta\", \"\")\n",
    "quarter_data_folder = os.path.join(parent_folder,\"datasets\", \"quarter_new_Si_jaw_delta\", \"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Adata = data_acquisition.getData([\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"A\"], folder_path)\n",
    "Bdata = data_acquisition.getData([\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"B\"], folder_path)\n",
    "Cdata = data_acquisition.getData([\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"C\"], folder_path)\n",
    "Csdata = data_acquisition.get_Standarized_data(\"cScaler\",[\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"C\"], folder_path)\n",
    "Bsdata = data_acquisition.get_Standarized_data(\"bScaler\",[\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"B\"], folder_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_set_r2(model, x,y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)\n",
    "        pred = pred.flatten().tolist()\n",
    "    y= y.flatten().tolist()\n",
    "    return (pearsonr(pred, y)[0]**2)\n",
    "\n",
    "def calculate_r2(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predTrain = model(data[0])\n",
    "        predTrain = predTrain.flatten().tolist()\n",
    "        predTest = model(data[2])\n",
    "        predTest = predTest.flatten().tolist()\n",
    "        yTrain = data[1].flatten().tolist()\n",
    "        yTest = data[3].flatten().tolist()\n",
    "    return ([pearsonr(predTrain, yTrain)[0]**2, pearsonr(predTest, yTest)[0]**2])\n",
    "\n",
    "A_32_16_16_8 = create_and_load(model_folder, \"modelA_32_16_16_8.pth\", 7, 1)\n",
    "print(f\"modelA_32_16_16_8 R2 Train: {calculate_r2(A_32_16_16_8, Adata)[0]} Test: {calculate_r2(A_32_16_16_8, Adata)[1]}\")\n",
    "A_48_32_24_12 = create_and_load(model_folder, \"modelA_48_32_24_12.pth\", 7, 1)\n",
    "print(f\"modelA_48_32_24_12 R2 Train: {calculate_r2(A_48_32_24_12, Adata)[0]} Test: {calculate_r2(A_48_32_24_12, Adata)[1]}\")\n",
    "A_64_32_32_16 = create_and_load(model_folder, \"modelA_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelA_64_32_32_16 R2 Train: {calculate_r2(A_64_32_32_16, Adata)[0]} Test: {calculate_r2(A_64_32_32_16, Adata)[1]}\")\n",
    "B_32_16_16_8 = create_and_load(model_folder, \"modelB_32_16_16_8.pth\", 7, 1)\n",
    "print(f\"modelB_32_16_16_8 R2 Train: {calculate_r2(B_32_16_16_8, Bdata)[0]} Test: {calculate_r2(B_32_16_16_8, Bdata)[1]}\")\n",
    "B_48_32_24_12 = create_and_load(model_folder, \"modelB_48_32_24_12.pth\", 7, 1)\n",
    "print(f\"modelB_48_32_24_12 R2 Train: {calculate_r2(B_48_32_24_12, Bdata)[0]} Test: {calculate_r2(B_48_32_24_12, Bdata)[1]}\")\n",
    "B_64_32_32_16 = create_and_load(model_folder, \"modelB_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelB_64_32_32_16 R2 Train: {calculate_r2(B_64_32_32_16, Bdata)[0]} Test: {calculate_r2(B_64_32_32_16, Bdata)[1]}\")\n",
    "C_32_16_16_8 = create_and_load(model_folder, \"modelC_32_16_16_8.pth\", 7, 1)\n",
    "print(f\"modelC_32_16_16_8 R2 Train: {calculate_r2(C_32_16_16_8, Cdata)[0]} Test: {calculate_r2(C_32_16_16_8, Cdata)[1]}\")\n",
    "C_48_32_24_12 = create_and_load(model_folder, \"modelC_48_32_24_12.pth\", 7, 1)\n",
    "print(f\"modelC_48_32_24_12 R2 Train: {calculate_r2(C_48_32_24_12, Cdata)[0]} Test: {calculate_r2(C_48_32_24_12, Cdata)[1]}\")\n",
    "C_64_32_32_16 = create_and_load(model_folder, \"modelC_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelC_64_32_32_16 R2 Train: {calculate_r2(C_64_32_32_16, Cdata)[0]} Test: {calculate_r2(C_64_32_32_16, Cdata)[1]}\")\n",
    "\n",
    "Cst_32_16_16_8 = create_and_load(model_folder, \"modelCstandard_32_16_16_8.pth\", 7, 1)\n",
    "print(f\"modelCstandard_32_16_16_8 R2 Train: {calculate_r2(Cst_32_16_16_8, Csdata)[0]} Test: {calculate_r2(Cst_32_16_16_8, Csdata)[1]}\")\n",
    "Cst_48_32_24_12 = create_and_load(model_folder, \"modelCstandard_48_32_24_12.pth\", 7, 1)\n",
    "print(f\"modelCstandard_48_32_24_12 R2 Train: {calculate_r2(Cst_48_32_24_12, Csdata)[0]} Test: {calculate_r2(Cst_48_32_24_12, Csdata)[1]}\")\n",
    "Cst_64_32_32_16 = create_and_load(model_folder, \"modelCstandard_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelCstandard_64_32_32_16 R2 Train: {calculate_r2(Cst_64_32_32_16, Csdata)[0]} Test: {calculate_r2(Cst_64_32_32_16, Csdata)[1]}\")\n",
    "Bst_32_16_16_8 = create_and_load(model_folder, \"modelBstandard_32_16_16_8.pth\", 7, 1)\n",
    "print(f\"modelBstandard_32_16_16_8 R2 Train: {calculate_r2(Bst_32_16_16_8, Bsdata)[0]} Test: {calculate_r2(Bst_32_16_16_8, Bsdata)[1]}\")\n",
    "Bst_48_32_24_12 = create_and_load(model_folder, \"modelBstandard_48_32_24_12.pth\", 7, 1)\n",
    "print(f\"modelBstandard_48_32_24_12 R2 Train: {calculate_r2(Bst_48_32_24_12, Bsdata)[0]} Test: {calculate_r2(Bst_48_32_24_12, Bsdata)[1]}\")\n",
    "Bst_64_32_32_16 = create_and_load(model_folder, \"modelBstandard_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelBstandard_64_32_32_16 R2 Train: {calculate_r2(Bst_64_32_32_16, Bsdata)[0]} Test: {calculate_r2(Bst_64_32_32_16, Bsdata)[1]}\")\n",
    "\n",
    "csXdatacombined = torch.cat((Csdata[0], Csdata[2]), dim=0)\n",
    "csYdatacombined = torch.cat((Csdata[1], Csdata[3]), dim=0)\n",
    "bsXdatacombined = torch.cat((Bsdata[0], Bsdata[2]), dim=0)\n",
    "bsYdatacombined = torch.cat((Bsdata[1], Bsdata[3]), dim=0)\n",
    "\n",
    "print(f\"combined modelCstandard_64_32_32_16 R2: {calculate_set_r2(Cst_64_32_32_16, csXdatacombined, csYdatacombined)}\")\n",
    "print(f\"combined modelBstandard_64_32_32_16 R2: {calculate_set_r2(Bst_64_32_32_16, bsXdatacombined, bsYdatacombined)}\")\n",
    "print(f\"combined modelCstandard_48_32_24_12 R2: {calculate_set_r2(Cst_48_32_24_12, csXdatacombined, csYdatacombined)}\")\n",
    "print(f\"combined modelBstandard_48_32_24_12 R2: {calculate_set_r2(Bst_48_32_24_12, bsXdatacombined, bsYdatacombined)}\")\n",
    "print(f\"combined modelCstandard_32_16_16_8 R2: {calculate_set_r2(Cst_32_16_16_8, csXdatacombined, csYdatacombined)}\")\n",
    "print(f\"combined modelBstandard_32_16_16_8 R2: {calculate_set_r2(Bst_32_16_16_8, bsXdatacombined, bsYdatacombined)}\")\n",
    "\n",
    "\n",
    "\n",
    "cshalfdata = data_acquisition.get_Standarized_data(\"cScaler\",[\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"C\"], half_data_folder)\n",
    "bshalfdata = data_acquisition.get_Standarized_data(\"bScaler\",[\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"B\"], half_data_folder)\n",
    "\n",
    "\n",
    "c_half_64_32_32_16 = create_and_load(model_folder, \"modelhalfCstandard_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelhalfCstandard_64_32_32_16 R2 Train: {calculate_r2(c_half_64_32_32_16, cshalfdata)[0]} Test: {calculate_r2(c_half_64_32_32_16, cshalfdata)[1]}\")\n",
    "b_half_64_32_32_16 = create_and_load(model_folder, \"modelhalfBstandard_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelhalfBstandard_64_32_32_16 R2 Train: {calculate_r2(b_half_64_32_32_16, bshalfdata)[0]} Test: {calculate_r2(b_half_64_32_32_16, bshalfdata)[1]}\")\n",
    "\n",
    "cs_halfX_data_combined = torch.cat((cshalfdata[0], cshalfdata[2]), dim=0)\n",
    "cs_halfY_data_combined = torch.cat((cshalfdata[1], cshalfdata[3]), dim=0)\n",
    "bs_halfX_data_combined = torch.cat((bshalfdata[0], bshalfdata[2]), dim=0)\n",
    "bs_halfY_data_combined = torch.cat((bshalfdata[1], bshalfdata[3]), dim=0)\n",
    "\n",
    "print(f\"combined modelhalfCstandard_64_32_32_16 R2: {calculate_set_r2(c_half_64_32_32_16, cs_halfX_data_combined, cs_halfY_data_combined)}\")\n",
    "print(f\"combined modelhalfBstandard_64_32_32_16 R2: {calculate_set_r2(b_half_64_32_32_16, bs_halfX_data_combined, bs_halfY_data_combined)}\")\n",
    "\n",
    "\n",
    "\n",
    "cquarterdata = data_acquisition.get_Standarized_data(\"cScaler\",[\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"C\"], quarter_data_folder)\n",
    "bquarterdata = data_acquisition.get_Standarized_data(\"bScaler\",[\"wavelength\",\"psi65\", \"del65\", \"psi70\", \"del70\", \"psi75\", \"del75\"], [\"B\"], quarter_data_folder)\n",
    "\n",
    "\n",
    "c_quarter_64_32_32_16 = create_and_load(model_folder, \"modelquarterCstandard_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelquarterCstandard_64_32_32_16 R2 Train: {calculate_r2(c_quarter_64_32_32_16, cquarterdata)[0]} Test: {calculate_r2(c_quarter_64_32_32_16, cquarterdata)[1]}\")\n",
    "\n",
    "b_quarter_64_32_32_16 = create_and_load(model_folder, \"modelquarterBstandard_64_32_32_16.pth\", 7, 1)\n",
    "print(f\"modelquarterBstandard_64_32_32_16 R2 Train: {calculate_r2(b_quarter_64_32_32_16, bquarterdata)[0]} Test: {calculate_r2(b_quarter_64_32_32_16, bquarterdata)[1]}\")\n",
    "\n",
    "\n",
    "cs_halfX_data_combined = torch.cat((cquarterdata[0], cquarterdata[2]), dim=0)\n",
    "cs_halfY_data_combined = torch.cat((cquarterdata[1], cquarterdata[3]), dim=0)\n",
    "bs_halfX_data_combined = torch.cat((bquarterdata[0], bquarterdata[2]), dim=0)\n",
    "bs_halfY_data_combined = torch.cat((bquarterdata[1], bquarterdata[3]), dim=0)\n",
    "print(f\"combined modelquarterCstandard_64_32_32_16 R2: {calculate_set_r2(c_quarter_64_32_32_16, cs_halfX_data_combined, cs_halfY_data_combined)}\")\n",
    "print(f\"combined modelquarterBstandard_64_32_32_16 R2: {calculate_set_r2(b_quarter_64_32_32_16, bs_halfX_data_combined, bs_halfY_data_combined)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8fb3a-c335-4907-9001-480a3e2c2210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
