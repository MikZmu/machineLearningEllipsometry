{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f63bf0cd-5f77-4fb7-a42d-d3a3f5b43575",
   "metadata": {},
   "source": [
    "Żadna z funkcji w tym notatniku nie jest przystosowana do użycia w Jupyter Notebooku.\n",
    "Właściwe pliki znajdują się w plikach .py w folderze clicker. Uczenie rozpoczynam z pliku MLP_playground.py Samo uczenie przeprowadzałem na Linuxie ze względu na wsparcie linuxa dla oprogramownia umożliwiającego mi wykorzystanie GPU marki Radeon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0467988b-6d73-4112-9920-403a4195370a",
   "metadata": {},
   "source": [
    "W komórce poniżej znajduje się klasa opisująca budowę sieci neuronowej. W celu konstrukcji klasy należy podać ilość neuronów w warstwie wejściowej,\n",
    "ilość neuronów w warstwie wyjściowej oraz ilość neuronów w warstwach ukrytych. Ilość warstw ukrytych nie może być większa niż 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce21c9f-6ad7-483b-944a-810055276ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, activation_fn=nn.ReLU):\n",
    "\n",
    "        super(MLP, self).__init__()\n",
    "        if len(hidden_layers) > 5:\n",
    "            raise ValueError(\"The number of hidden layers cannot exceed 5.\")\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        prev_size = input_size\n",
    "\n",
    "        # Create hidden layers\n",
    "        for neurons in hidden_layers:\n",
    "            self.layers.append(nn.Linear(prev_size, neurons))\n",
    "            self.layers.append(activation_fn())  # Add the specified activation function\n",
    "            prev_size = neurons\n",
    "\n",
    "        # Create output layer\n",
    "        self.layers.append(nn.Linear(prev_size, output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a2021c-3461-4eb6-a4fc-2901db0b2b92",
   "metadata": {},
   "source": [
    "Poniższa funkcja pobiera dane z folderu \"datasets/new_Si_jaw_delta\". W folderze tym znajdują się pliki z danymi, które są wczytywane do ramki danych. Funkcja zwraca dane podzielone na zbiór treningowy i testowy. Zbiór treningowy i testowy są podzielone w stosunku 80% do 20%. Argument funkcji \"target_columns\" pozwala na określenie, które kolumny mają być przewidywane przez model. Domyślnie są to kolumny T, A, B i C. Funkcja zwraca dane w postaci tensorów PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "752b9593-b72d-48a4-a678-faf16bdfe08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def getData(target_columns=['T', 'A', 'B', 'C']):\n",
    "    project_folder = os.path.dirname(os.path.abspath(__file__))\n",
    "    folder_path = os.path.join(project_folder,\"datasets\", \"Si_jaw_delta\", \"\")\n",
    "    print(folder_path)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    all_items = os.listdir(folder_path)\n",
    "    print(all_items)\n",
    "\n",
    "    # Filter the list to include only files\n",
    "    files = [item for item in all_items if os.path.isfile(os.path.join(folder_path, item))]\n",
    "\n",
    "    dataFrame = pd.DataFrame()\n",
    "\n",
    "    newDataFrame = pd.DataFrame()\n",
    "\n",
    "    for i in files:\n",
    "        dataHelper = pd.read_csv(folder_path + i, sep='\\t', header=None, index_col=False)\n",
    "        info = i.split('_')\n",
    "        T = info[0]\n",
    "        A = info[1]\n",
    "        B = info[2]\n",
    "        C = info[3]\n",
    "        dataHelper = dataHelper.drop(index=[0])\n",
    "        dataHelper = dataHelper.drop(columns=[7])\n",
    "        dataHelper.columns = ['wavelength', 'psi65', 'del65', 'psi70', 'del70', 'psi75', 'del75']\n",
    "        dataHelper['T'] = T\n",
    "        dataHelper['A'] = A\n",
    "        dataHelper['B'] = B\n",
    "        C = C.removesuffix(\".txt\")\n",
    "\n",
    "        if (\"-\" in C):\n",
    "            C = C.removesuffix(\"e-\")\n",
    "            C = float(C) * 10 ** -5\n",
    "        elif (\"e\" in C):\n",
    "            C = C.removesuffix(\"e\")\n",
    "            C = float(C) * 10 ** -5\n",
    "\n",
    "        if (float(C) > 1):\n",
    "            C = float(C) * 10 ** -5\n",
    "\n",
    "        dataHelper['C'] = C\n",
    "        dataFrame = pd.concat([dataFrame, dataHelper], ignore_index=True)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        dataFrame[['wavelength', 'psi65', 'del65', 'psi70', 'del70', 'psi75', 'del75']],\n",
    "        dataFrame[target_columns],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    x_train = torch.from_numpy(x_train.values).float()\n",
    "    x_test = torch.from_numpy(x_test.values).float()\n",
    "    y_train = torch.from_numpy(y_train.to_numpy(dtype=np.float32))\n",
    "    y_test = torch.from_numpy(y_test.to_numpy(dtype=np.float32))\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d8594e-fe9f-4203-b60f-ff3b3aed2551",
   "metadata": {},
   "source": [
    "Poniższa funkcja zarządza procesem uczenia sieci neuronowej. Funkcja przyjmuje jako argumenty model, funkcję straty, optymalizator, dane treningowe i testowe oraz ścieżkę do zapisu modelu. Funkcja zapisuje model, jeśli jego strata jest mniejsza od najlepszej dotychczasowej straty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce4d91cd-1a74-4266-8b36-19add73df9c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'orca.orca_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clear_output\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01morca\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01morca_state\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m device\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model\u001b[39m(model, loss_fn, optimizer, x_train, y_train, x_test, y_test, save_path):\n\u001b[32m     11\u001b[39m     best_loss = \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'orca.orca_state'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import IPython\n",
    "from IPython.core.display_functions import clear_output\n",
    "from orca.orca_state import device\n",
    "\n",
    "\n",
    "def train_model(model, loss_fn, optimizer, x_train, y_train, x_test, y_test, save_path):\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    start_time = time.time()\n",
    "    times, losses = [], []\n",
    "    \"\"\"plt.ion()\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    model = model.to(device)\n",
    "    x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "    x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "\n",
    "\n",
    "    while True:\n",
    "        # Forward pass\n",
    "        outputs = model(x_train)\n",
    "        loss = loss_fn(outputs, y_train)\n",
    "        test_loss = loss_fn(model(x_test), y_test)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #if scheduler:\n",
    "         #   scheduler.step(loss)\n",
    "\n",
    "        # Record time and loss\n",
    "        elapsed_time = time.time() - start_time\n",
    "        times.append(elapsed_time)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"New best loss: {best_loss:.4f}. Model saved to {save_path}.\")\n",
    "\n",
    "        \"\"\"ax.clear()\n",
    "        ax.plot(times, losses, label=\"Training Loss\")\n",
    "        ax.set_xlabel(\"Time (seconds)\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.set_title(\"Loss vs Time\")\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "        plt.pause(0.01)  # Pause briefly to update the plot\"\"\"\n",
    "\n",
    "        print(f\"Current Loss: {loss.item():.8f}, Test Loss: {test_loss.item():.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6de8b48-018b-415f-97bd-8abc6653a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import MLP_class\n",
    "import  getData_class\n",
    "import training_class\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "model = MLP(input_size=7, output_size=1, hidden_layers=[128, 64, 64, 32])\n",
    "print(model)\n",
    "data = getData(['B'])\n",
    "print(data)\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=10)\n",
    "torch.cuda.empty_cache()\n",
    "training_class.train_model(model, loss, optimizer, x_train=data[0], y_train=data[1], x_test=data[2].squeeze(), y_test=data[3], save_path='modelB.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
